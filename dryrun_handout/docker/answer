#!/usr/bin/python3 -W ignore::DeprecationWarning
# -*- coding:utf8 -*-
import sys
import spacy
import re
import codecs
from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
import transformers

if __name__ == "__main__":
    input_file = sys.argv[1]#'./data/set1/a1.txt'
    question_file = sys.argv[2]#'./test_questions.txt'

    model_name = "deepset/roberta-base-squad2"
    # model_name = "distilbert-base-uncased-distilled-squad"
    # model_name = "bert-large-uncased-whole-word-masking-finetuned-squad"
    # model_name = "ktrapeznikov/albert-xlarge-v2-squad-v2"

    transformers.utils.logging.disable_progress_bar()
    nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
    
    with open(input_file, 'r') as f:
        text = f.read()

    with open(question_file, 'r') as f:
        count = 0
        for line in f:
            count += 1

            question = line.strip()
            QA_input = {"question": question, "context": text}
            res = nlp(QA_input)

            if res['answer'] == None:
                print('')
            else:
                print(res['answer'])
