#!/usr/bin/python3 -W ignore::DeprecationWarning
# -*- coding:utf8 -*-

import sys
from transformers import ProphetNetTokenizer, ProphetNetForConditionalGeneration#, ProphetNetConfig
from to_pronoun import change_to_noun
from preprocess_qg import context_preprocess, split_into_sentences
from paraphrase import paraphrase
import random

if __name__ == "__main__":
    # print("Let's start!")
    pronoun_model = change_to_noun()
    paraphrase_model = paraphrase()
    

    model = ProphetNetForConditionalGeneration.from_pretrained('microsoft/prophetnet-large-uncased-squad-qg')
    tokenizer = ProphetNetTokenizer.from_pretrained('microsoft/prophetnet-large-uncased-squad-qg')
    
    input_file = sys.argv[1] #/host/Users/data/set1/a1.txt
    # input_file = "host/Users/data/set1/a1.txt" #/host/Users/data/set1/a1.txt
    N = int(sys.argv[2]) #3
    

    # Open and Preprocess the given context
    # ********************************************************
    preprocessed_text = context_preprocess(input_file) 


    num_lines = len(preprocessed_text)


    for j in range(N):
        pronounX = [] 
        for mundan_num in range(3):
            i = random.randrange(len(preprocessed_text))
            mundan=preprocessed_text[i]
            pronounXM = pronoun_model.input_txt(mundan) 
            pronounXMS=split_into_sentences(pronounXM) 
            pronounX.extend(pronounXMS) 

        selected = []

        # prnonX : list
        for sent_num in range(len(pronounX)//5):
            i = random.randint(0,len(pronounX))
            temp = paraphrase_model.get_response(pronounX[i])
            selected.extend(temp)
            selected.append(pronounX[i])
        # print(selected)
        QG_input = " ".join(selected)


        inputs = tokenizer([QG_input], return_tensors='pt')
        question_ids = model.generate(inputs['input_ids'], num_beams=5, early_stopping=True)
        
        print((tokenizer.batch_decode(question_ids, skip_special_tokens=True)[0]))